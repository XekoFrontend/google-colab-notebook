{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1V-FCk6e_C-rynD2T8wm6pwBUbT_WLakF",
      "authorship_tag": "ABX9TyMO/n3C8DYoqPJ9tM2EjHEO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XekoFrontend/google-colab-notebook/blob/main/get_truyen3sqq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "qCK6O69KvULw",
        "outputId": "d0e3308c-3082-4929-bc2c-a7b9b9c12538"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-1024152985.py, line 22)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1024152985.py\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    ```for img in soup.find_all(\"img\"):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import time\n",
        "from urllib.parse import urlparse\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# ==== CONFIG ====\n",
        "URL = \"https://truyentranh3qq.com/vung-hoang-mac/chuong-2\"  # <-- ƒê·ªïi sang link chap m√†y mu·ªën\n",
        "SAVE_DIR = \"downloaded_images\"\n",
        "ZIP_FILE = \"chapter.cbz\"  # N·∫øu kh√¥ng c·∫ßn zip th√¨ b·ªè qua\n",
        "\n",
        "# T·∫°o th∆∞ m·ª•c\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# L·∫•y HTML trang\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "r = requests.get(URL, headers=headers)\n",
        "soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "# L·ªçc link ·∫£nh\n",
        "\"\"\"for img in soup.find_all(\"img\"):\n",
        "    src = img.get(\"src\") or img.get(\"data-src\") or img.get(\"data-original\")\n",
        "    if src and any(p in src for p in patterns):\n",
        "        img_links.append(src)\n",
        "```\n",
        "patterns = [\"h2.nettruyen\", \"sf-static.tiktokcdn.com\"]\n",
        "img_links = []\n",
        "\"\"\"\n",
        "patterns = [\"h2.nettruyen\", \"sf-static.tiktokcdn.com\"]\n",
        "img_links = []\n",
        "\n",
        "for img in soup.find_all(\"img\"):\n",
        "    src = img.get(\"src\") or img.get(\"data-src\") or img.get(\"data-original\")\n",
        "    if src and any(p in src for p in patterns):\n",
        "        img_links.append(src)\n",
        "\n",
        "print(f\"üéØ T√¨m th·∫•y {len(img_links)} ·∫£nh\")\n",
        "\n",
        "# T·∫£i ·∫£nh\n",
        "for i, link in enumerate(img_links, 1):\n",
        "    ext = os.path.splitext(urlparse(link).path)[1] or \".jpg\"\n",
        "    filename = f\"image-{i:03}{ext}\"\n",
        "    filepath = os.path.join(SAVE_DIR, filename)\n",
        "\n",
        "    try:\n",
        "        img_data = requests.get(link, headers=headers).content\n",
        "        with open(filepath, \"wb\") as f:\n",
        "            f.write(img_data)\n",
        "        print(f\"‚úÖ {filename} t·∫£i xong\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå L·ªói t·∫£i {link}: {e}\")\n",
        "\n",
        "    time.sleep(3)  # delay 3s tr√°nh b·ªã block\n",
        "\n",
        "# N√©n th√†nh CBZ (n·∫øu c·∫ßn)\n",
        "if ZIP_FILE:\n",
        "    with ZipFile(ZIP_FILE, \"w\") as zipf:\n",
        "        for file in os.listdir(SAVE_DIR):\n",
        "            zipf.write(os.path.join(SAVE_DIR, file), file)\n",
        "    print(f\"üì¶ ƒê√£ t·∫°o {ZIP_FILE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4 requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Peotyq3W3s9w",
        "outputId": "5ba26abf-83d8-4f35-fe8e-64d1ee1026c0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import random\n",
        "from urllib.parse import urlparse, urljoin\n",
        "from zipfile import ZipFile\n",
        "from pathlib import Path\n",
        "\n",
        "# ==== CONFIG ====\n",
        "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "PATTERNS = [\"h2.nettruyen\", \"sf-static.tiktokcdn.com\"]\n",
        "DELAY = (2.5, 4.0)  # delay ng·∫´u nhi√™n gi·ªØa m·ªói ·∫£nh\n",
        "\n",
        "# ==== H√ÄM ====\n",
        "\n",
        "def get_soup(url):\n",
        "    r = requests.get(url, headers=HEADERS, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    return BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "def safe_join(base, url):\n",
        "    if not url:\n",
        "        return None\n",
        "    if url.startswith(\"//\"):\n",
        "        return \"https:\" + url\n",
        "    return urljoin(base, url)\n",
        "\n",
        "def extract_chapter_number(href):\n",
        "    m = re.search(r\"/chuong-(\\d+)\", href)\n",
        "    return int(m.group(1)) if m else None\n",
        "\n",
        "def list_chapters(title_url):\n",
        "    soup = get_soup(title_url)\n",
        "    base = \"{uri.scheme}://{uri.netloc}\".format(uri=urlparse(title_url))\n",
        "    chapters = {}\n",
        "    for a in soup.find_all(\"a\", href=True):\n",
        "        href = safe_join(base, a[\"href\"])\n",
        "        num = extract_chapter_number(href)\n",
        "        if num is not None:\n",
        "            chapters[num] = href\n",
        "    return sorted(chapters.items())\n",
        "\n",
        "def find_images(chapter_url):\n",
        "    soup = get_soup(chapter_url)\n",
        "    img_links = []\n",
        "    for img in soup.find_all(\"img\"):\n",
        "        src = img.get(\"src\") or img.get(\"data-src\") or img.get(\"data-original\")\n",
        "        if src and any(p in src for p in PATTERNS):\n",
        "            img_links.append(src)\n",
        "    return img_links\n",
        "\n",
        "def download_chapter(chap_num, chap_url, series_dir):\n",
        "    print(f\"\\n=== Chapter {chap_num} ===\")\n",
        "    imgs = find_images(chap_url)\n",
        "    print(f\"üñºÔ∏è {len(imgs)} ·∫£nh t√¨m th·∫•y\")\n",
        "\n",
        "    chap_dir = series_dir / f\"chapter-{chap_num:03d}\"\n",
        "    chap_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for i, link in enumerate(imgs, 1):\n",
        "        ext = os.path.splitext(urlparse(link).path)[1] or \".jpg\"\n",
        "        filename = f\"image-{i:03}{ext}\"\n",
        "        filepath = chap_dir / filename\n",
        "        try:\n",
        "            img_data = requests.get(link, headers=HEADERS).content\n",
        "            with open(filepath, \"wb\") as f:\n",
        "                f.write(img_data)\n",
        "            print(f\"‚úÖ {filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå L·ªói {link}: {e}\")\n",
        "        time.sleep(random.uniform(*DELAY))\n",
        "\n",
        "    # zip -> cbz\n",
        "    cbz_path = series_dir / f\"chapter-{chap_num:03d}.cbz\"\n",
        "    with ZipFile(cbz_path, \"w\") as zipf:\n",
        "        for file in sorted(chap_dir.iterdir()):\n",
        "            zipf.write(file, arcname=file.name)\n",
        "    print(f\"üì¶ ƒê√£ t·∫°o {cbz_path.name}\")\n",
        "\n",
        "def parse_selection(sel, available):\n",
        "    sel = sel.strip().lower()\n",
        "    if sel == \"all\":\n",
        "        return sorted(available)\n",
        "    result = set()\n",
        "    for part in sel.split(\",\"):\n",
        "        part = part.strip()\n",
        "        if \"-\" in part:\n",
        "            a, b = part.split(\"-\", 1)\n",
        "            try:\n",
        "                a, b = int(a), int(b)\n",
        "                for x in range(min(a, b), max(a, b) + 1):\n",
        "                    if x in available:\n",
        "                        result.add(x)\n",
        "            except:\n",
        "                pass\n",
        "        else:\n",
        "            try:\n",
        "                x = int(part)\n",
        "                if x in available:\n",
        "                    result.add(x)\n",
        "            except:\n",
        "                pass\n",
        "    return sorted(result)\n",
        "\n",
        "# ==== MAIN ====\n",
        "title_url = input(\"D√°n link trang truy·ªán (trang t·ªïng): \").strip()\n",
        "series_slug = Path(urlparse(title_url).path.rstrip(\"/\")).name or \"series\"\n",
        "series_dir = Path(series_slug)\n",
        "series_dir.mkdir(exist_ok=True)\n",
        "\n",
        "chapters = list_chapters(title_url)\n",
        "if not chapters:\n",
        "    print(\"‚ùå Kh√¥ng t√¨m th·∫•y chapter n√†o.\")\n",
        "    exit()\n",
        "\n",
        "available_nums = [n for n, _ in chapters]\n",
        "print(f\"T·ªïng s·ªë chapter: {len(available_nums)}\")\n",
        "print(f\"Danh s√°ch: {available_nums}\")\n",
        "\n",
        "sel = input(\"Ch·ªçn chapter (all | 1-5 | 1,3,7): \").strip() or \"all\"\n",
        "chosen = parse_selection(sel, available_nums)\n",
        "if not chosen:\n",
        "    print(\"‚ùå Kh√¥ng ch·ªçn ƒë∆∞·ª£c chapter h·ª£p l·ªá.\")\n",
        "    exit()\n",
        "\n",
        "chap_map = dict(chapters)\n",
        "for num in chosen:\n",
        "    download_chapter(num, chap_map[num], series_dir)\n",
        "\n",
        "print(\"\\nüéâ Ho√†n t·∫•t!\")\n",
        "print(f\"- ·∫¢nh theo chapter: {series_dir}/chapter-XXX\")\n",
        "print(f\"- CBZ theo chapter: {series_dir}/chapter-XXX.cbz\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPsAymgtyGcI",
        "outputId": "655c43d1-04a7-4a18-fe5c-2b7a7f040426"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "D√°n link trang truy·ªán (trang t·ªïng): https://truyentranh3qq.com/vung-hoang-mac\n",
            "T·ªïng s·ªë chapter: 14\n",
            "Danh s√°ch: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
            "Ch·ªçn chapter (all | 1-5 | 1,3,7): 5-14\n",
            "\n",
            "=== Chapter 5 ===\n",
            "üñºÔ∏è 14 ·∫£nh t√¨m th·∫•y\n",
            "‚úÖ image-001.jpg\n",
            "‚úÖ image-002.jpg\n",
            "‚úÖ image-003.jpg\n",
            "‚úÖ image-004.jpg\n",
            "‚úÖ image-005.jpg\n",
            "‚úÖ image-006.jpg\n",
            "‚úÖ image-007.jpg\n",
            "‚úÖ image-008.jpg\n",
            "‚úÖ image-009.jpg\n",
            "‚úÖ image-010.jpg\n",
            "‚úÖ image-011.jpg\n",
            "‚úÖ image-012.jpg\n",
            "‚úÖ image-013.jpg\n",
            "‚úÖ image-014.jpg\n",
            "üì¶ ƒê√£ t·∫°o chapter-005.cbz\n",
            "\n",
            "=== Chapter 6 ===\n",
            "üñºÔ∏è 14 ·∫£nh t√¨m th·∫•y\n",
            "‚úÖ image-001.jpg\n",
            "‚úÖ image-002.jpg\n",
            "‚úÖ image-003.jpg\n",
            "‚úÖ image-004.jpg\n",
            "‚úÖ image-005.jpg\n",
            "‚úÖ image-006.jpg\n",
            "‚úÖ image-007.jpg\n",
            "‚úÖ image-008.jpg\n",
            "‚úÖ image-009.jpg\n",
            "‚úÖ image-010.jpg\n",
            "‚úÖ image-011.jpg\n",
            "‚úÖ image-012.jpg\n",
            "‚úÖ image-013.jpg\n",
            "‚úÖ image-014.jpg\n",
            "üì¶ ƒê√£ t·∫°o chapter-006.cbz\n",
            "\n",
            "=== Chapter 7 ===\n",
            "üñºÔ∏è 14 ·∫£nh t√¨m th·∫•y\n",
            "‚úÖ image-001.jpg\n",
            "‚úÖ image-002.jpg\n",
            "‚úÖ image-003.jpg\n",
            "‚úÖ image-004.jpg\n",
            "‚úÖ image-005.jpg\n",
            "‚úÖ image-006.jpg\n",
            "‚úÖ image-007.jpg\n",
            "‚úÖ image-008.jpg\n",
            "‚úÖ image-009.jpg\n",
            "‚úÖ image-010.jpg\n",
            "‚úÖ image-011.jpg\n",
            "‚úÖ image-012.jpg\n",
            "‚úÖ image-013.jpg\n",
            "‚úÖ image-014.jpg\n",
            "üì¶ ƒê√£ t·∫°o chapter-007.cbz\n",
            "\n",
            "=== Chapter 8 ===\n",
            "üñºÔ∏è 15 ·∫£nh t√¨m th·∫•y\n",
            "‚úÖ image-001.jpg\n",
            "‚úÖ image-002.jpg\n",
            "‚úÖ image-003.jpg\n",
            "‚úÖ image-004.jpg\n",
            "‚úÖ image-005.jpg\n",
            "‚úÖ image-006.jpg\n",
            "‚úÖ image-007.jpg\n",
            "‚úÖ image-008.jpg\n",
            "‚úÖ image-009.jpg\n",
            "‚úÖ image-010.jpg\n",
            "‚úÖ image-011.jpg\n",
            "‚úÖ image-012.jpg\n",
            "‚úÖ image-013.jpg\n",
            "‚úÖ image-014.jpg\n",
            "‚úÖ image-015.jpg\n",
            "üì¶ ƒê√£ t·∫°o chapter-008.cbz\n",
            "\n",
            "=== Chapter 9 ===\n",
            "üñºÔ∏è 14 ·∫£nh t√¨m th·∫•y\n",
            "‚úÖ image-001.jpg\n",
            "‚úÖ image-002.jpg\n",
            "‚úÖ image-003.jpg\n",
            "‚úÖ image-004.jpg\n",
            "‚úÖ image-005.jpg\n",
            "‚úÖ image-006.jpg\n",
            "‚úÖ image-007.jpg\n",
            "‚úÖ image-008.jpg\n",
            "‚úÖ image-009.jpg\n",
            "‚úÖ image-010.jpg\n",
            "‚úÖ image-011.jpg\n",
            "‚úÖ image-012.jpg\n",
            "‚úÖ image-013.jpg\n",
            "‚úÖ image-014.jpg\n",
            "üì¶ ƒê√£ t·∫°o chapter-009.cbz\n",
            "\n",
            "=== Chapter 10 ===\n",
            "üñºÔ∏è 15 ·∫£nh t√¨m th·∫•y\n",
            "‚úÖ image-001.jpg\n",
            "‚úÖ image-002.jpg\n",
            "‚úÖ image-003.jpg\n",
            "‚úÖ image-004.jpg\n",
            "‚úÖ image-005.jpg\n",
            "‚úÖ image-006.jpg\n",
            "‚úÖ image-007.jpg\n",
            "‚úÖ image-008.jpg\n",
            "‚úÖ image-009.jpg\n",
            "‚úÖ image-010.jpg\n",
            "‚úÖ image-011.jpg\n",
            "‚úÖ image-012.jpg\n",
            "‚úÖ image-013.jpg\n",
            "‚úÖ image-014.jpg\n",
            "‚úÖ image-015.jpg\n",
            "üì¶ ƒê√£ t·∫°o chapter-010.cbz\n",
            "\n",
            "=== Chapter 11 ===\n",
            "üñºÔ∏è 14 ·∫£nh t√¨m th·∫•y\n",
            "‚úÖ image-001.jpg\n",
            "‚úÖ image-002.jpg\n",
            "‚úÖ image-003.jpg\n",
            "‚úÖ image-004.jpg\n",
            "‚úÖ image-005.jpg\n",
            "‚úÖ image-006.jpg\n",
            "‚úÖ image-007.jpg\n",
            "‚úÖ image-008.jpg\n",
            "‚úÖ image-009.jpg\n",
            "‚úÖ image-010.jpg\n",
            "‚úÖ image-011.jpg\n",
            "‚úÖ image-012.jpg\n",
            "‚úÖ image-013.jpg\n",
            "‚úÖ image-014.jpg\n",
            "üì¶ ƒê√£ t·∫°o chapter-011.cbz\n",
            "\n",
            "=== Chapter 12 ===\n",
            "üñºÔ∏è 15 ·∫£nh t√¨m th·∫•y\n",
            "‚úÖ image-001.jpg\n",
            "‚úÖ image-002.jpg\n",
            "‚úÖ image-003.jpg\n",
            "‚úÖ image-004.jpg\n",
            "‚úÖ image-005.jpg\n",
            "‚úÖ image-006.jpg\n",
            "‚úÖ image-007.jpg\n",
            "‚úÖ image-008.jpg\n",
            "‚úÖ image-009.jpg\n",
            "‚úÖ image-010.jpg\n",
            "‚úÖ image-011.jpg\n",
            "‚úÖ image-012.jpg\n",
            "‚úÖ image-013.jpg\n",
            "‚úÖ image-014.jpg\n",
            "‚úÖ image-015.jpg\n",
            "üì¶ ƒê√£ t·∫°o chapter-012.cbz\n",
            "\n",
            "=== Chapter 13 ===\n",
            "üñºÔ∏è 15 ·∫£nh t√¨m th·∫•y\n",
            "‚úÖ image-001.jpg\n",
            "‚úÖ image-002.jpg\n",
            "‚úÖ image-003.jpg\n",
            "‚úÖ image-004.jpg\n",
            "‚úÖ image-005.jpg\n",
            "‚úÖ image-006.jpg\n",
            "‚úÖ image-007.jpg\n",
            "‚úÖ image-008.jpg\n",
            "‚úÖ image-009.jpg\n",
            "‚úÖ image-010.jpg\n",
            "‚úÖ image-011.jpg\n",
            "‚úÖ image-012.jpg\n",
            "‚úÖ image-013.jpg\n",
            "‚úÖ image-014.jpg\n",
            "‚úÖ image-015.jpg\n",
            "üì¶ ƒê√£ t·∫°o chapter-013.cbz\n",
            "\n",
            "=== Chapter 14 ===\n",
            "üñºÔ∏è 12 ·∫£nh t√¨m th·∫•y\n",
            "‚úÖ image-001.jpg\n",
            "‚úÖ image-002.jpg\n",
            "‚úÖ image-003.jpg\n",
            "‚úÖ image-004.jpg\n",
            "‚úÖ image-005.jpg\n",
            "‚úÖ image-006.jpg\n",
            "‚úÖ image-007.jpg\n",
            "‚úÖ image-008.jpg\n",
            "‚úÖ image-009.jpg\n",
            "‚úÖ image-010.jpg\n",
            "‚úÖ image-011.jpg\n",
            "‚úÖ image-012.jpg\n",
            "üì¶ ƒê√£ t·∫°o chapter-014.cbz\n",
            "\n",
            "üéâ Ho√†n t·∫•t!\n",
            "- ·∫¢nh theo chapter: vung-hoang-mac/chapter-XXX\n",
            "- CBZ theo chapter: vung-hoang-mac/chapter-XXX.cbz\n"
          ]
        }
      ]
    }
  ]
}